# 📚 스터디 기록 (2025-08-13)

---

## 🔍 공부 내용
- **퍼셉트론(Perceptron)**
  - 인공신경망의 가장 기초 단위
  - 입력값 × 가중치 → 활성함수 → 출력
  - 딥러닝이 데이터를 처리하는 과정을 이해하는 데 도움

---

## 🧠 머신러닝 학습 방식
- **지도학습 (Supervised Learning)**  
  → 입력과 정답(레이블) 제공, 모델 학습  
  ✅ 예시: 이미지 분류  

- **비지도학습 (Unsupervised Learning)**  
  → 정답 없이 패턴·군집 탐색  
  ✅ 예시: 클러스터링, 차원 축소  

- **강화학습 (Reinforcement Learning)**  
  → 환경과 상호작용하며 보상 기반 학습  
  ✅ 예시: 게임 플레이, 로봇 제어  

---

## ⚡ 활성함수 (Activation Function)
- **Sigmoid**  
  - 출력: 0~1  
  - 특징: 확률 해석 가능  
  - ⚠️ 단점: 기울기 소실 문제 발생  

- **Tanh**  
  - 출력: -1~1  
  - 특징: Sigmoid보다 중심화된 값 제공  
  - ⚠️ 단점: 여전히 기울기 소실 문제 존재  

- **ReLU**  
  - 특징: 계산 속도 빠름  
  - ⚠️ 단점: Dead ReLU 문제 발생  

- **Leaky ReLU**  
  - 특징: ReLU 단점 보완, 음수 영역에 작은 기울기 부여  

- **Softmax**  
  - 특징: 출력층에서 확률 분포 제공  

---

## ✏️ 느낀 점
- 퍼셉트론은 단순해 보이지만 딥러닝의 핵심 출발점
- 활성함수 선택이 모델 성능에 큰 영향
- **다음 학습 계획**
  - 다층 퍼셉트론(MLP)
  - Backpropagation

---
